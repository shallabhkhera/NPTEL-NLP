{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let us define an HMM Model with $K$ classes of hidden states and $T$ data points as observations. The data-set is defined as $\\textbf{X}= \\{x_1,x_2,x_3....x_T\\}$ and the corresponding hidden states as $\\textbf{Z} = \\{ z_1,z_2,z_3......z_T \\}$. Please note that each $x_i$ is an observed variable and each $z_i$ can belong to one of classes $ \\{ 1 ... K \\} $. What will be the size of the state transition matrix, $ \\textbf{A} $ and the emission matrix, $ \\Phi $ respectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Since there are K hidden states, the state transition matrix will be of size $ K \\times K$. The emission matrix will be of size $ K \\times T $, as it defines the probability of emitting an observed state from a given hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "For an HMM, The initial state distribution is given as $ P(z_{1}) = \\pi_{z_{1}} $. The emission distribution is a vector parametrised by $ \\phi_{. k} $, where $ \\phi_{xk} = P(x_{i} = x | z_{i} = k) $, and $ \\Phi $ is the emission matrix that contains all the vectors $ \\phi_{. k} $ . The transition probabilities are given as $ a_{kj} = P(z_t = k | z_{t-1} = j) $. Let $ \\Theta = \\{\\textbf{A},\\Phi, \\pi \\} $.\n",
    "What is the full likelihood of the observed and hidden variables, $P( \\textbf{X},\\textbf{Z} | \\Theta)$, if given:\n",
    "\n",
    "$$ P( \\textbf{X},\\textbf{Z} | \\Theta) = P( \\textbf{X}|\\textbf{Z},\\Theta)P(\\textbf{Z} | \\Theta) = \\prod_{t=1}^T P(x_t|z_t)P(z_1)\\prod_{t=2}^T P(z_t|z_{t-1}) = \\textbf{Q}\n",
    "$$\n",
    "\n",
    "What is $\\textbf{Q}$\n",
    " \n",
    " $$\\prod_{k=1}^K \\pi_{z_{1}}^{\\delta_(z_{1k})} \\prod_{t=1}^T\\prod_{k=2}^K\\prod_{j=3}^K \\phi_{x_tk}^{\\delta(z_{tk})} \\prod_{t=1}^T\\prod_{k=1}^K  a_{jk}^{\\delta(z_{tk}z_{t-1j})} $$\n",
    " \n",
    " $$\\prod_{k=1}^K \\pi_{z_{1}}^{\\delta_(z_{1k})} \\prod_{t=1}^T\\prod_{k=1}^K\\prod_{j=2}^K a_{jk}^{\\delta(z_{tk}z_{t-1j})}\\prod_{t=1}^T\\prod_{k=1}^K \\phi_{x_tk}^{\\delta(z_{tk})}$$\n",
    " \n",
    " $$\\prod_{k=1}^K \\pi_{z_{1}}^{\\delta_(z_{1k})} \\prod_{t=1}^T\\prod_{k=1}^K\\prod_{j=1}^K a_{jk}^{\\delta(z_{tk}z_{t-1j})}\\prod_{t=1}^T\\prod_{k=1}^K \\phi_{x_tk}^{\\delta(z_{tk})}$$\n",
    " \n",
    "  None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "$\\prod_{k=1}^K \\pi_{z_{1}}^{\\delta_(z_{1k})} \\prod_{t=1}^T\\prod_{k=1}^K\\prod_{j=1}^K a_{jk}^{\\delta(z_{tk}z_{t-1j})}\\prod_{t=1}^T\\prod_{k=1}^K \\phi_{x_tk}^{\\delta(z_{tk})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "For an HMM, what is the speed-up that Viterbi algorithm provides when compared to the exhaustive searching algorithm, in terms of K and T where K and T follows the same definition as given above. \n",
    "Hint The speed up is the division of worst case time complexity of exhausitve search by that of the viterbi algorithm\n",
    "\n",
    "$$K^2 T $$\n",
    "$$ K^{T-2} T^{-1} $$\n",
    "$$ K^{TK} log T $$\n",
    "$$T^K $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Exhaustive search has a time complexity of of $ K^{T} $. [Viterbi algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm) has a worst case time complexity of $ K^{2}T $.\n",
    "\n",
    "So the division of both gives the correct answer $$ K^{T-2} T^{-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Match the following\n",
    "\n",
    "### Solution\n",
    "\n",
    "Marginalisation - We marginalise over S $$ P(O) = \\sum_s P(O,S) $$   \n",
    "\n",
    "Chain rule - The joint probability is expressed in terms of chain of conditional probability expressions\n",
    "$$P(H,S,F) = P(H)P(S|H)P(F|S,H)$$\n",
    "Order-1 Markov - Only the immediate previous entry is considered\n",
    "$$P(X_t = i | X_{t-1},X_{t-2}......X_0) = P(X_t = i |X_{t-1})$$\n",
    "Time invariance - The  position (or time point, assuming it as a time series) in which the observation has appeared does not matter\n",
    "$$P(X_t = i | X_{t-1} = j) = P(X_1 = i | X_{0} = j) = P(X_2 = i | X_{1} = j) = .... = P(X_n = i | X_{n-1} = j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the trnasition probability from $K2$ to $H5$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is 0.5\n",
    "\n",
    "As the probability of tansition from K2 to any state should sum upto 1\n",
    "ALso, proability of K2 to H1 is 0.5. K2 to K2 is 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "What is the emission probability for the state H5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "$ 0.1, 0.2, 0.5, 0.2 $\n",
    "\n",
    "Its stated that \"The state transition diagram below shows the combined probability of filling cash at a particular ATM and then deciding on the denomination to be filled next.\"\n",
    "\n",
    "Now consider the transition probability from $H5$ to $K2$. The value is $0.1$\n",
    "\n",
    "Now consider the values in the arc directed from $H5$ to $K2$\n",
    "the values are 0.01,0.02,0.05,0.02\n",
    "\n",
    "Now, as mentioned for the state diagram, first the ATM is located and then moves to decide the denomination\n",
    "\n",
    "so $ 0.1 \\times x1 $ = 0.01\n",
    "   $ 0.1 \\times x2 $ = 0.02\n",
    "   and so on\n",
    "   \n",
    " Here 0.1 is the state transition probability.\n",
    " \n",
    " Hence the emission probability results in the value given above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "In the state transition diagram fill in the missing values for the arc from H1 to K2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Emission probablity at state H1 is $ 0.6 , 0.2, 0.1, 0.1 $\n",
    "\n",
    "Transition probability from H1 to K2 is 0.1\n",
    "\n",
    "So the missing values are product each emission probability with 0.1\n",
    "\n",
    "\n",
    "A1 = 0.06, A2 = 0.02, A3 = 0.01, A4 = 0.01 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "For the given observation smallX = “A1,A1,A3,A1,A2,A3,A3”, find out the most likely path(s) of the hidden states. There can be multiple state sequences with same score. In that case, report all the paths. You may modify the exhaustive search function to obtain multiple paths. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answers are H1,H1,H1,H1,H1,H5,H5  and H1,H1,H1,H1,H5,H5,H5\n",
    "\n",
    "You were suposed to modify the function exhaustive as given in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exhaustive(params, observations):\n",
    "    pi, A, O = params\n",
    "    M = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    # track the running best sequence and its score\n",
    "    best = (None, float('-inf'))\n",
    "    # loop over the cartesian product of |states|^M\n",
    "    bestDict = dict()\n",
    "    for ss in product(range(S), repeat=M):\n",
    "        # score the state sequence\n",
    "        score = pi[ss[0]] * O[ss[0],observations[0]]\n",
    "        for i in range(1, M):\n",
    "            score *= A[ss[i-1], ss[i]] * O[ss[i], observations[i]]\n",
    "        # update the running best\n",
    "        if score >= best[1]:\n",
    "            best = (ss, score)\n",
    "            try:\n",
    "                bestDict[score].append((ss,score))\n",
    "            except:\n",
    "                bestDict[score] = []\n",
    "                bestDict[score].append((ss,score))\n",
    "    print bestDict  \n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "Find and report an observation sequence that differs from smallX (Refer to the previous question) to the minimal extent possible, for which the most-likely state sequence is all H5s, i.e., denomination of Rs. 500 is filled continuously for 7 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "The answers are : A3,A1,A3,A1,A2,A3,A3 and A4,A1,A3,A1,A2,A3,A3 \n",
    "    \n",
    "Executing the method exhaustive (given or modified) should show a state sequence of all H5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "For the observation sequence \"\"A1, A1, A3, A1, A2, A3, A3, A4, A4, A4, A4, A4, A4, A4, A1, A1, A3, A3, A4, A3, A4, A3, A4, A2, A2, A2, A4, A4, A3, A1, A2, A1, A1, A2, A3, A2, A2, A2, A4, A4, A4, A4, A3, A4, A3, A3, A2, A3'', what is the hidden state for the final substring \"A3, A2, A3''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here using the method \"exhaustive\" might not yield you a result. You should be using the vterbi algorithm here. Just rememebr the time complexity for both the methods.\n",
    "\n",
    "The answer is \"H5,H5,H5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "Based on the evidence above, assume we defined a feature set of 5 features for a maximum entropy model that can model this distribution. Which of the following is least likely to be a feature in the feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "1 if tag = N and wi+1 (next word) ends in 'ed' , else 0\n",
    "\n",
    "\n",
    "All the others match with one of the feature descitptions. So only this one remain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "Consider the following sentence: 'Sue purchased Zantec in Arcadia'. For this sentence, and for the entry P(P|Sue), how many among the 5 features as per the model have the value 1, such that only the weights of those features will be considered for the expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Here only one feature is valid for P(P|Sue), which is \n",
    "\n",
    "if tag = P and the next word ends in ed. For Sue, the next word is purcahsed"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
