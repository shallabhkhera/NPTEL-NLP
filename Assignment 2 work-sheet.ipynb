{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "- For questions 5,6,7 use the function `levenshtein`\n",
    "- For question 6, modify the function `levenshtein` on the variable `substitutions`\n",
    "- For question 8, use the function `jaro_winkler`. The function is defined in the file `Edistance.py`\n",
    "- For questions 5 to 10, the function `uniFreq` is needed to calculate the count of unigrams in the corpus $C_3$\n",
    "- For question 9, the function `bigramFreq` is needed to calculate the count of bigrams in the corpus $C_3$\n",
    "- For question 10, use the code snippet given in the last cell\n",
    "\n",
    "## Files\n",
    "- use unigram.csv for questions 5,6,7,8\n",
    "- use bigrams.csv for questions 9,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniFreq():\n",
    "    unigrams = open('unigram.csv').read().splitlines()\n",
    "    wordFreq = dict()\n",
    "    for word in unigrams:\n",
    "        item = word.split(',')\n",
    "        wordFreq[item[0].strip()] = int(item[1].strip())\n",
    "    return wordFreq\n",
    "\n",
    "def bigramFreq():\n",
    "    bigrams =  open('bigrams.csv').read().splitlines()\n",
    "    wordBigram = dict()\n",
    "    for word in bigrams:\n",
    "        item = word.split(',')\n",
    "        wordBigram[item[0].strip()] = int(item[1].strip())\n",
    "    return wordBigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function Definition starts with def <function name> (<input arguments>)\n",
    "# 2 strings to comapre, hence 2 inputs as arguments\n",
    "\n",
    "# mind the indentation\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            # cost for each of 3 operations.\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2) # if true returns one, oterwise 0\n",
    "            \n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaro Winkler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866666666667\n"
     ]
    }
   ],
   "source": [
    "from Edistance import jaro_winkler\n",
    "print jaro_winkler('bimal','vimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaro Winkler Distance\n",
    "\n",
    "The Jaro–Winkler distance is a measure of similarity between two strings.  The Jaro-Winkler similarity is given by `1 - Jaro Winkler distance`. The Jaro–Winkler distance metric is designed and best suited for short strings such as person names. The similarity score is normalized such that 0 equates to no similarity and 1 is an exact match.\n",
    "\n",
    "$ d_{j}=\\left\\{{\\begin{array}{ll}0&{\\text{if }}m=0\\\\{\\frac  {1}{3}}\\left({\\frac  {m}{|s_{1}|}}+{\\frac  {m}{|s_{2}|}}+{\\frac  {m-t}{m}}\\right)&{\\text{otherwise}}\\end{array}}\\right. $\n",
    "\n",
    "\n",
    "Where \n",
    "- **s1** and **s2** are the strings \n",
    "- **m** is the number of matching characters (see below);\n",
    "- **t** is half the number of transpositions (see below).\n",
    "\n",
    "Source - [Jaro-Winkler Distance (Wikipedia)](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFreq = uniFreq()\n",
    "wordBigram = bigramFreq()\n",
    "def bigram_likelihood(bigramWord1,word1,word2,uniDict=wordFreq,biDict=wordBigram):\n",
    "    bi = biDict[bigramWord1]\n",
    "    uni = uniDict[word1]\n",
    "\n",
    "    print bi,uni\n",
    "\n",
    "    bigramProb = bi/(uni*1.0)\n",
    "    return bigramProb\n",
    "\n",
    "bigram_likelihood('iron safe','iron','safe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-one smoothing for finding likelihood of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00980244307043 <s> sandip\n",
      "0.00905109489051 sandip babu\n",
      "0.000149075730471 babu sang\n",
      "0.000150784077201 sang bande\n",
      "0.00584883023395 bande mataram\n",
      "0.000149970005999 mataram </s>\n",
      "0.000150806816468 </s>\n",
      "1.74932821106e-18\n",
      "0.000904840898809 <s> chandranath\n",
      "0.00180695678362 chandranath babu\n",
      "0.000149075730471 babu asked\n",
      "0.0001495215311 asked for\n",
      "for\n",
      "0.000301477238468 betel leaves\n",
      "0.000150625094141 leaves </s>\n",
      "0.000150806816468 </s>\n",
      "1.65494105455e-21\n",
      "0.00120645453174 <s> poor\n",
      "0.00045051809581 poor bimala\n",
      "0.000297707651087 bimala went\n",
      "0.00014905351021 went to\n",
      "0.000150693188668 to the\n",
      "0.000150715900528 the dressing\n",
      "0.00105342362679 dressing room\n",
      "0.000148345942738 room </s>\n",
      "0.000150806816468 </s>\n",
      "8.56025744882e-29\n"
     ]
    }
   ],
   "source": [
    "wordFreq['<s>'] = 1\n",
    "wordFreq['</s>'] = 1\n",
    "stri2 = ['<s> sandip babu sang bande mataram </s>','<s> chandranath babu asked for betel leaves </s>','<s> poor bimala went to the dressing room </s>']\n",
    "for stri in stri2:\n",
    "    mult = 1.0\n",
    "    for i,item in enumerate(stri.split(' ')):\n",
    "        try:\n",
    "            print (wordBigram[item+' '+stri.split()[i+1]] + 1)/((wordFreq[item] + len(wordFreq.keys()))*1.0),item+' '+stri.split()[i+1]\n",
    "            mult = mult * (wordBigram[item+' '+stri.split()[i+1]] + 1)/((wordFreq[item] + len(wordFreq.keys()))*1.0)\n",
    "        except:\n",
    "            try:\n",
    "                print (1)/((wordFreq[item] + len(wordFreq.keys()))*1.0),item+' '+stri.split()[i+1]\n",
    "                mult = mult * (1)/((wordFreq[item] + len(wordFreq.keys()))*1.0)\n",
    "            except:\n",
    "                print item\n",
    "    print mult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
