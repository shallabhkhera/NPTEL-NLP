{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "\n",
    "- All the document in the collection share the same set of topics, but each document exhibits those topics in different proportions\n",
    "\n",
    "- Each word in each document is drawn from one of the topics, where the selected topic is chosen from the per-document distribution over topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the library, `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): gensim in /home/amrith/anaconda2/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5.0 in /home/amrith/anaconda2/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy>=0.7.0 in /home/amrith/anaconda2/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied (use --upgrade to upgrade): smart-open>=1.2.1 in /home/amrith/anaconda2/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.3 in /home/amrith/anaconda2/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests in /home/amrith/anaconda2/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied (use --upgrade to upgrade): boto>=2.32 in /home/amrith/anaconda2/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied (use --upgrade to upgrade): bz2file in /home/amrith/anaconda2/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tiny corpus of nine documents, each consisting of only a single sentence.\n",
    "\n",
    "First, let’s tokenize the documents, remove common words (using a toy stoplist) as well as words that only appear once in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Find all words which occur more than 1 time in the corpus (of 9 documents)\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "\n",
    "from pprint import pprint  # pretty-printer\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('deerwester.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'minors': 11, u'graph': 10, u'system': 6, u'trees': 9, u'eps': 8, u'computer': 1, u'survey': 5, u'user': 7, u'human': 2, u'time': 4, u'interface': 0, u'response': 3}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `doc2bow()` simply counts the number of occurrences of each distinct word, converts the word to its integer word id and returns the result as a sparse vector. The sparse vector `[(word_id, 1), (word_id, 1)]` therefore reads: in the document *“Human computer interaction”*, the words *\"computer\"* and *\"human\"*, identified by an integer id given by the built dictionary, appear once; the other ten dictionary words appear (implicitly) zero times. Check their id at the dictionary displayed in the previous cell and see that they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(0, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[(2, 1), (6, 2), (8, 1)]\n",
      "[(3, 1), (4, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(5, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('deerwester.mm', corpus)  # store to disk, for later use\n",
    "for c in corpus:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel\n",
    "import numpy\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
       " [(0, 1), (2, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (7, 1)],\n",
       " [(0, 1), (2, 1), (3, 2), (8, 1)],\n",
       " [(0, 1), (2, 1), (5, 1), (9, 1)],\n",
       " [(3, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(3, 1), (10, 1), (13, 1)],\n",
       " [(3, 1), (12, 1)],\n",
       " [(3, 1), (10, 1), (12, 1), (14, 1)],\n",
       " [(13, 1), (14, 1)],\n",
       " [(3, 1), (14, 1), (15, 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [['bank','river','shore','water'],\n",
    "        ['river','water','flow','fast','tree'],\n",
    "        ['bank','water','fall','flow'],\n",
    "        ['bank','bank','water','rain','river'],\n",
    "        ['river','water','mud','tree'],\n",
    "        ['money','transaction','bank','finance'],\n",
    "        ['bank','borrow','money'], \n",
    "        ['bank','finance'],\n",
    "        ['finance','money','sell','bank'],\n",
    "        ['borrow','sell'],\n",
    "        ['bank','loan','sell']]\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(1) # setting random seed to get the same results each time.\n",
    "model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.164*\"bank\" + 0.142*\"water\" + 0.108*\"river\" + 0.076*\"flow\" + 0.067*\"borrow\" + 0.063*\"sell\" + 0.060*\"tree\" + 0.048*\"money\" + 0.046*\"fast\" + 0.044*\"rain\"'),\n",
       " (1,\n",
       "  u'0.196*\"bank\" + 0.120*\"finance\" + 0.100*\"money\" + 0.082*\"sell\" + 0.067*\"river\" + 0.065*\"water\" + 0.056*\"transaction\" + 0.049*\"loan\" + 0.046*\"tree\" + 0.040*\"mud\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.12821234071249418), (1, 0.047247458568794511)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.017179349495865623), (1, 0.10331511184214655)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_term_topics('finance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [0, 1]), (3, [0, 1])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_water = ['bank','water','bank']\n",
    "bow_finance = ['bank','finance','bank']\n",
    "\n",
    "bow = model.id2word.doc2bow(bow_water) # convert to bag of words format first\n",
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "\n",
    "word_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what does that output mean? It means that like `word_type 1`, our `word_type` `3`, which is the word `bank`, is more likely to be in `topic_0` than `topic_1`.\n",
    "\n",
    "You must have noticed that while we unpacked into `doc_topics` and `word_topics`, there is another variable - `phi_values`. Like the name suggests, phi_values contains the phi values for each topic for that particular word, scaled by feature length. Phi is essentially the probability of that word in that document belonging to a particular topic. The next few lines should illustrate this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [(0, 0.92486455564294345), (1, 0.075135444357056574)]),\n",
       " (3, [(0, 1.5817120973072454), (1, 0.41828790269275457)])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that `word_type` 0 has the following phi_values for each of the topics. \n",
    "What is intresting to note is `word_type` 3 - because it has 2 occurences (i.e, the word `bank` appears twice in the bow), we can see that the scaling by feature length is very evident. The sum of the phi_values is 2, and not 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, [1, 0]), (12, [1, 0])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bow = model.id2word.doc2bow(bow_finance) # convert to bag of words format first\n",
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "\n",
    "word_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.83270647275828524), (1, 0.16729352724171465)]\n",
      "Word topics: [(0, [0, 1]), (1, [0, 1]), (2, [0, 1]), (3, [0, 1])]\n",
      "Phi values: [(0, [(0, 0.96021858877561728), (1, 0.039781411224382848)]), (1, [(0, 0.8792197968627381), (1, 0.12078020313726202)]), (2, [(0, 0.9436416410382692), (1, 0.056358358961730817)]), (3, [(0, 0.88116401400740607), (1, 0.11883598599259385)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.90379559943992582), (1, 0.096204400560074191)]\n",
      "Word topics: [(0, [0, 1]), (2, [0, 1]), (4, [0]), (5, [0, 1]), (6, [0])]\n",
      "Phi values: [(0, [(0, 0.98551395531215857), (1, 0.014486044687841437)]), (2, [(0, 0.97924982750620249), (1, 0.020750172493797691)]), (4, [(0, 0.99280849901823975)]), (5, [(0, 0.97529774122781776), (1, 0.024702258772182139)]), (6, [(0, 0.99004205057244832)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.87507219282484316), (1, 0.12492780717515681)]\n",
      "Word topics: [(0, [0, 1]), (3, [0, 1]), (4, [0, 1]), (7, [0, 1])]\n",
      "Phi values: [(0, [(0, 0.9783234200583657), (1, 0.021676579941634355)]), (3, [(0, 0.93272653621872503), (1, 0.067273463781275009)]), (4, [(0, 0.98919912227661466), (1, 0.010800877723385368)]), (7, [(0, 0.97541896333079636), (1, 0.024581036669203641)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.87853819958920043), (1, 0.12146180041079963)]\n",
      "Word topics: [(0, [0, 1]), (2, [0, 1]), (3, [0, 1]), (8, [0, 1])]\n",
      "Phi values: [(0, [(0, 0.97596134249481492), (1, 0.024038657505185145)]), (2, [(0, 0.96571015226994938), (1, 0.034289847730050532)]), (3, [(0, 1.8515455755053762), (1, 0.14845442449462368)]), (8, [(0, 0.97848202469975276), (1, 0.02151797530024737)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.8564463740623548), (1, 0.14355362593764515)]\n",
      "Word topics: [(0, [0, 1]), (2, [0, 1]), (5, [0, 1]), (9, [0, 1])]\n",
      "Phi values: [(0, [(0, 0.97074863890671426), (1, 0.029251361093285921)]), (2, [(0, 0.95836933362205601), (1, 0.041630666377943999)]), (5, [(0, 0.95064079648593458), (1, 0.049359203514065461)]), (9, [(0, 0.9030358276222904), (1, 0.096964172377709559)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.11549963646117181), (1, 0.88450036353882822)]\n",
      "Word topics: [(3, [1, 0]), (10, [1, 0]), (11, [1]), (12, [1])]\n",
      "Phi values: [(3, [(0, 0.040062133454181567), (1, 0.95993786654581814)]), (10, [(0, 0.020103806467996799), (1, 0.97989619353200308)]), (11, [(1, 0.9910494032913304)]), (12, [(1, 0.99174412290358549)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.4438859314607822), (1, 0.55611406853921774)]\n",
      "Word topics: [(3, [1, 0]), (10, [1, 0]), (13, [0, 1])]\n",
      "Phi values: [(3, [(0, 0.38381806344612612), (1, 0.61618193655387399)]), (10, [(0, 0.2344281158270084), (1, 0.76557188417299149)]), (13, [(0, 0.65651736899869417), (1, 0.34348263100130555)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.20199255912939526), (1, 0.79800744087060471)]\n",
      "Word topics: [(3, [1, 0]), (12, [1, 0])]\n",
      "Phi values: [(3, [(0, 0.086998287940481228), (1, 0.91300171205951863)]), (12, [(0, 0.018652395463982233), (1, 0.98134760453601788)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.12505726157782684), (1, 0.87494273842217329)]\n",
      "Word topics: [(3, [1, 0]), (10, [1, 0]), (12, [1]), (14, [1, 0])]\n",
      "Phi values: [(3, [(0, 0.047837589620218293), (1, 0.95216241037978167)]), (10, [(0, 0.024102914052397461), (1, 0.9758970859476026)]), (12, [(1, 0.99007797561579536)]), (14, [(0, 0.043092845513997391), (1, 0.95690715448600261)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.72319610071601936), (1, 0.27680389928398064)]\n",
      "Word topics: [(13, [0, 1]), (14, [0, 1])]\n",
      "Phi values: [(13, [(0, 0.91396121153662713), (1, 0.086038788463372942)]), (14, [(0, 0.75627751890080031), (1, 0.24372248109919972)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "New Document \n",
      "\n",
      "Document topics: [(0, 0.16978578818257647), (1, 0.8302142118174235)]\n",
      "Word topics: [(3, [1, 0]), (14, [1, 0]), (15, [1, 0])]\n",
      "Phi values: [(3, [(0, 0.075528355267193981), (1, 0.92447164473280596)]), (14, [(0, 0.068233937712710413), (1, 0.93176606228728953)]), (15, [(0, 0.035035615878295769), (1, 0.96496438412170416)])]\n",
      " \n",
      "-------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_topics = model.get_document_topics(corpus, per_word_topics=True)\n",
    "\n",
    "for doc_topics, word_topics, phi_values in all_topics:\n",
    "    print('New Document \\n')\n",
    "    print 'Document topics:', doc_topics\n",
    "    print 'Word topics:', word_topics\n",
    "    print 'Phi values:', phi_values\n",
    "    print(\" \")\n",
    "    print('-------------- \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
